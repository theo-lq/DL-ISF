{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7cDc2dVX2D1"
   },
   "source": [
    "# Séance 4 - Réseau récurrent\n",
    "\n",
    "Dans cette séance nous allons entraîner un modèle à copier le style de poésie de Beaudelaire, spécifiquement l'oeuvre *Les fleurs du mal*. Ce TP est largement inspiré du cours du [CNAM](https://cedric.cnam.fr/~thomen/cours/US330X/tpRNNs.html) que l'on a adapté ici.\n",
    "\n",
    "Pour cela, nous utiliserons le projet [Gutenberg](https://www.gutenberg.org) qui permet l'accès l'ensemble des oeuvres littéraires classique gratuitement. C'est sur ce dataset, entre autres, que les LLM s'entraînent.\n",
    "\n",
    "Commençons par importer les packages dont nous aurons besoin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pe1mrRDtYaBM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set(style=\"whitegrid\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "InTQRzhkY6My"
   },
   "source": [
    "Après avoir chargé dans l'environnement le fichier .txt de poésie, nous devons le travailler un peu pour l'exploiter. Quand on regarde le détail du fichier, on voit qu'il y a du texte qui n'est pas de la poésie. Nous décidons de n'exploiter que les poèmes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hkSTixun__Xw"
   },
   "outputs": [],
   "source": [
    "start = False\n",
    "book = open(\"Beaudelaire.txt\", 'r' , encoding = 'utf8')\n",
    "lines = book.readlines()\n",
    "verses = []\n",
    "\n",
    "for line in lines:\n",
    " line = line.strip().lower()\n",
    " if(\"AU LECTEUR\".lower() in line and start==False):\n",
    "  start = True\n",
    " if(\"End of the Project Gutenberg EBook of Les Fleurs du Mal, by Charles Baudelaire\".lower() in line):\n",
    "  break\n",
    " if(start==False or len(line) == 0):\n",
    "  continue\n",
    " verses.append(line)\n",
    "\n",
    "book.close()\n",
    "text = \" \".join(verses)\n",
    "characters = sorted(set([character for character in text]))\n",
    "n_characters = len(characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7626TUDbZHVf"
   },
   "source": [
    "On décide ici de le découper en séquence de 32 caractères et de se décaler d'un caractère à chaque fois. Nous allons donc prédire le caractère suivant à partir des 32 caractères précédents.\n",
    "Construisons deux listes qui, une fois transformée, deviendront $X$ et $y$.\n",
    "\n",
    "**Consigne** : Compléter la cellule suivante avec les informations précédentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uO403MyQAzim"
   },
   "outputs": [],
   "source": [
    "sequence_length = ...\n",
    "stride = 1\n",
    "sequences = []\n",
    "y_character = []\n",
    "for index in range(0, len(text) - sequence_length, stride):\n",
    " ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12vayeAWZaAo"
   },
   "source": [
    "Un réseau de neurone ne comprend pas le texte, donc nous devrons jongler entre nombre et caractères. Pour cela, nous créons deux dictionnaires pour traduire ces deux visions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rGkZx3JQB3gn"
   },
   "outputs": [],
   "source": [
    "character_to_index = dict((character, index) for index, character in enumerate(characters))\n",
    "index_to_character = dict((index, character) for index, character in enumerate(characters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4er_XSvHZljl"
   },
   "source": [
    "Nous sommes maintenant prêt pour renseigner $X$ et $y$. La matrice $X$ sera de taille $n \\times N \\times C$ avec:\n",
    "* $n$ : le nombre de séquence exemples\n",
    "* $N$ : la longueur de la séquence que l'on considère, ici 32\n",
    "* $C$ : le nombre de caractères différents, ici stocké dans la variable *n_characters*\n",
    "\n",
    "La matrice $y$ sera de taille $n\\times C$. Les deux matrices seront de types booléens avec la valeur *True* à l'index du caractères représenté.\n",
    "\n",
    "**Consigne** : Remplir la cellule suivante avec les informations précédentes. On utilisera le dictionnaire *character_to_index*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3b5vdYJ_DO8y"
   },
   "outputs": [],
   "source": [
    "X = np.zeros((len(sequences), sequence_length, n_characters), dtype=bool)\n",
    "y = np.zeros((len(sequences), n_characters), dtype=bool)\n",
    "\n",
    "for row, sequence in enumerate(sequences):\n",
    "  for position, character in enumerate(sequence):\n",
    "    #Remplir X\n",
    "  #Remplir y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GhrZsGulZs6U"
   },
   "source": [
    "Découpons à présent $X$ et $y$ en un jeu de test et un jeu d'entraînement. Aussi, nous allons sauvegarder ces matrices au cas où nous souhaiterions ne pas avoir à relancer ce preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b37hlbPmFUd6"
   },
   "outputs": [],
   "source": [
    "import _pickle as pickle\n",
    "\n",
    "train_size = 0.8\n",
    "train_index = int(round(len(sequences)*train_size))\n",
    "X_train = X[:train_index,:,:]\n",
    "y_train = y[:train_index,:]\n",
    "\n",
    "X_test = X[train_index:,:,:]\n",
    "y_test = y[train_index:,:]\n",
    "\n",
    "\n",
    "outfile = \"Baudelaire_len_%d.p\" % sequence_length\n",
    "\n",
    "with open(outfile, \"wb\") as pickle_f:\n",
    " pickle.dump([index_to_character, X_train, y_train, X_test, y_test], pickle_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-zzNAhSZ7pA"
   },
   "source": [
    "## Modélisation\n",
    "\n",
    "Dans cet exemple, nous allons définir un réseau récurrent avec les neurones de bases : pas de LSTM ou GRU.\n",
    "\n",
    "Un neurone *SimpleRNN* possède les mêmes attributs qu'un neurones classique en plus de deux paramètres majeurs:\n",
    "* **return_sequences**: si l'on doit renvoyer la totalité de la séquence ou seulement la dernière valeur\n",
    "* **unroll**: permet d'accélérer l'entraînement du réseau de neurone au prix de plus de mémoire impliquée\n",
    "\n",
    "**Consigne** : Compléter la cellule suivante pour définir le réseau de neurones avec les informations précédentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "muGo3GElW-6l"
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    #Ajouter une couche SimpleRNN\n",
    "    #Ajouter une couche de LayerNormalization\n",
    "    #Ajouter une couche SimpleRNN\n",
    "    #Ajouter une couche Dense\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLfT59Q3adf9"
   },
   "source": [
    "Pour éviter l'overfitting, on se propose d'exploiter la mécanique d'[EarlyStopping](https://keras.io/api/callbacks/early_stopping/).\n",
    "\n",
    "**Consigne** : Compléter la cellule suivante pour compiler le réseau de neurones et l'entraîner avec la mécanique d'EarlyStopping à paramétrer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jk1g8higXtED"
   },
   "outputs": [],
   "source": [
    "callback = keras.callbacks.EarlyStopping(...)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=..., metrics=[\"accuracy\"])\n",
    "history = model.fit(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnYgg07XaxtI"
   },
   "source": [
    "L'entraînement étant terminé, visualisons sa courbe d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qsPvn4t6XuuK"
   },
   "outputs": [],
   "source": [
    "historic = pd.DataFrame(history.history)\n",
    "figure, (axis_1, axis_2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "epochs = range(1, n_epochs+1)\n",
    "\n",
    "for index, (metric_name, axis) in enumerate(zip([\"loss\", \"accuracy\"], [axis_1, axis_2])):\n",
    "  color = sns.color_palette()[index]\n",
    "  axis.plot(epochs, historic[metric_name], lw=2, color=color)\n",
    "  axis.plot(epochs, historic[\"val_\" + metric_name], ls=\"--\", color=color)\n",
    "\n",
    "  if metric_name == \"accuracy\": axis.set_ylim(0, 1)\n",
    "  axis.set_ylabel(metric_name.capitalize())\n",
    "  axis.set_xlabel(\"Epochs\")\n",
    "  axis.set_title(\"%s through training\" % metric_name.capitalize())\n",
    "\n",
    "\n",
    "plt.suptitle(\"RNN Training\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56NMPwxOa8I9"
   },
   "source": [
    "Sauvegardons le modèle pour pouvoir l'utiliser plus tard, ou sur un autre notebook par exemple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sS2kjywjGx8_"
   },
   "outputs": [],
   "source": [
    "def save_model(model, name):\n",
    "  model_json = model.to_json()\n",
    "  with open(name + \".json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "  model.save_weights(name+\".h5\")\n",
    "\n",
    "save_model(model, \"SimpleRNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UqMSdzSbX06B"
   },
   "source": [
    "Importons le modèle que l'on vient de sauvegarder sous un autre alias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FRVCXsVOHQx-"
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "\n",
    "def load_model(name):\n",
    "  with open(name + \".json\", \"r\") as json_file:\n",
    "    model = model_from_json(json_file.read())\n",
    "  model.load_weights(name+\".h5\")\n",
    "  return model\n",
    "\n",
    "\n",
    "model_SimpleRNN = load_model(\"SimpleRNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1UKNXx4lbD4g"
   },
   "source": [
    "**Consignes** : Compléter la cellule suivante pour vérifier que les performances sont bien celles que nous connaissons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AhFyJkrbX-bn"
   },
   "outputs": [],
   "source": [
    "model_SimpleRNN.compile(loss='categorical_crossentropy', optimizer=...,metrics=['accuracy'])\n",
    "score = model_SimpleRNN.evaluate(...)\n",
    "print(\"Test accuracy: %.02f%%\" % (score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DzMrZFmKbVfL"
   },
   "source": [
    "## Génération de texte\n",
    "\n",
    "On souhaite exploiter le modèle pour générer de la poésie dans le style de Beaudelaire.\n",
    "On se propose de commencer par un bout d'un poème au hasard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2025\n",
    "sequence = \"\"\n",
    "for index in range(sequence_length):\n",
    " character = index_to_character[np.argmax(X_train[seed, index, :])]\n",
    " sequence += character\n",
    "\n",
    "print(\"Start sequence: \" + sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NeGrigxYa9lj"
   },
   "source": [
    "Pour choisir le prochain caractère, nous pouvons simplement sélectionner le caractère le plus probable prédit par le modèle. Cette approche peut amener le modèle à dégénérer.\n",
    "\n",
    "Nous allons essayer de sélectionner aléatoirement l'index du prochain caractère en s'appuyant sur le vecteur de probabilité produit par le réseau de neurone définit plus tôt.\n",
    "\n",
    "**Consigne** : A l'aide de la fonction [np.random.multinomial](https://numpy.org/doc/stable/reference/random/generated/numpy.random.multinomial.html), sélectionner un index aléatoirement selon un vecteur de probabilité à construire aléatoirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OkE9Dd9Ua9W3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eu6NDVX6bpLn"
   },
   "source": [
    "Nous allons en pratiue exploiter le *temperature sampling* pour sélectionner le prochain caractère.\n",
    "\n",
    "### Température\n",
    "\n",
    "On considère un vecteur $u = (u_1, u_2, \\ldots, u_d)$ et un paramètre $\\tau > 0$ que l'on appelle la température. On peut construire le vecteur $v = (v_1, v_2, \\ldots, v_d)$ à partir de $u$ et de $\\tau$ comme:\n",
    "\n",
    "$$\\forall i \\leqslant d, \\quad v_i = \\frac{\\displaystyle \\exp\\left(\\frac{u_i}{\\tau}\\right)}{\\displaystyle \\sum_{j=1}^d \\exp\\left(\\frac{u_j}{\\tau}\\right)}$$\n",
    "\n",
    "Cela ressemble à la fonction softmax mais paramétrer par la température $\\tau$.\n",
    "\n",
    "**Consigne** : Ecrire une fonction nommé `sampling` qui prend en paramètre un vecteur de probabilité et la température. Cette fonction doit renvoyer un index sélectionné selon le vecteur de probabilité définit par la température. On s'appuiera sur le travail de la cellule précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jeglw8biH6E8"
   },
   "outputs": [],
   "source": [
    "def sampling(...):\n",
    " ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9i1JrHL-cCAq"
   },
   "source": [
    "Maintenant que nous sommes capables de sélectionner le prochain caractère avec plus de justesse, il ne nous restes plus qu'à générer la suite de la phrase !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "faT74GT7PkJt"
   },
   "outputs": [],
   "source": [
    "def generate_sequence(start, length, model, temperature=1):\n",
    "  sequence = np.zeros((1, sequence_length, n_characters), dtype=bool)\n",
    "  for position, character in enumerate(start):\n",
    "    sequence[0][position][character_to_index[character]] = True\n",
    "\n",
    "  generated_sequence = start\n",
    "\n",
    "\n",
    "  for _ in range(length):\n",
    "    probabilities = model.predict(sequence, verbose=0)[0]\n",
    "    next_index = sampling(probabilities, temperature=temperature)\n",
    "    character = index_to_character[next_index]\n",
    "    generated_sequence += character\n",
    "\n",
    "    for index in range(sequence_length-1): sequence[0, index, :] = sequence[0, index+1, :]\n",
    "\n",
    "    sequence[0, sequence_length-1, :] = 0\n",
    "    sequence[0, sequence_length-1, next_index] = 1\n",
    "\n",
    "\n",
    "  return generated_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4Rm2tKib-md"
   },
   "source": [
    "Avec l'ensemble du travail, on a :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qvHtwn9ZcC-t"
   },
   "outputs": [],
   "source": [
    "generate_sequence(start=sequence, length=50, model=model_SimpleRNN, temperature=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BYX-wJDHcazG"
   },
   "source": [
    "**Consignes** : Définir et comparer d'autres architectures de réseau de neurones pour répondre à ce problème. On conseille d'observer les performances avec les courbes d'apprentissage mais aussi avec plusieurs génération de texte.\n",
    "\n",
    "## Pour continuer\n",
    "\n",
    "Choisir une ou plusieurs pistes de recherche parmi les suivantes. Il est possible de choisir une autre direction, mais elle doit être validé auparavant.\n",
    "\n",
    "1. Nous avons défini une seule architecture. On peut en essayer d'autres et les comparer à la fois avec les courbes d'apprentissages mais également avec la génération de texte.\n",
    "2. Il existe une couche [`Embedding`](https://keras.io/api/layers/core_layers/embedding/). On se propose de l'exploiter et de mesurer ses performances.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
